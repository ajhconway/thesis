\section{Background}\label{sec:fsa-background}

This section gives the background necessary to understand and analyze
the performance of \wod-betrfsd file systems, with a focus on \bets and
\betrfs.
% This section reviews background on write-optimized
% data structures.  At points, discussion focuses on \bets{},
% the particular WOD this paper uses.
See Bender et al.~\cite{bender15login} for  a more comprehensive
tutorial. 

\subsection{Write-Optimized Dictionaries}
\label{ssec:wods}

%WODS 
\wods
include Log-Structured Merge
Trees (\lsms)~\cite{OneilChGa96} and their variants~\cite{SearsRa12, ShettySpMa13, wu15atc},
\bets~\cite{BrodalFa03b}, 
xDicts~\cite{BrodalDeFi10},
and
cache-oblivious lookahead arrays (COLAs)~\cite{BenderFaFi07,santry14atc}.
\wods provide a key-value interface supporting insert, query, delete, and
range-query operations.

The \wod interface is similar to that of a B-tree, but the performance
profile is different:
\begin{compactitem}
%   \setlength\itemsep{-.1em}

\item \wods can perform inserts of random keys orders of magnitude
  faster than B-trees.  On a rotating disk, a B-tree can perform only
  a couple of hundred inserts per second in the worst case, whereas a
  \wod can perform many tens of thousands.

\item In \wods, a delete is implemented by inserting a tombstone message,
  which is extremely fast.

\item Some \wods, such as \bets, can perform point queries 
  % (i.e., look up the value associated with a single key)
  as fast as a B-tree. \bets (but not LSM-trees) offer a
  provably optimal combination of query and insert performance.

\item \wods perform range queries at nearly disk bandwidth.
  Because a \wod can use nodes over a megabyte in size,
  % (versus tens to hundreds of kilobytes in a B-tree), 
  a scan requires less than one disk seek per MB of data and
  hence is bandwidth bound.
\end{compactitem}

\vspace{5pt}
The key idea behind write optimization is deferring and batching
small, random writes.  A \bet logs
insertions or deletions as \emph{messages} at the root of the tree,
and only flushes messages down a level in the tree when enough
messages have accrued to offset the cost of accessing the child.  As a
result, a single message may be written to disk multiple times.
Since each message is always written as part of a larger batch, the amortized
cost for each insert is typically much less than one I/O.  In
comparison, writing a random element to a large B-tree requires a
minimum of one I/O.


% In theory, WODS can perform large sequential inserts at speeds
 % proportional to disk bandwidth.  
%   However, m
Most production-quality \wods
are engineered for use in databases,
not in file systems, and are therefore designed with different
performance requirements. For example, the open-source \wod implementation
underlying \betrfs is a port of 
%TokuDB\footnote{TokuDB implements \bet variant called 
%  \ftis~\cite{FractalTreeIndex15,BenderFaFi07}.}~\cite{TokuDB},
TokuDB\footnote{TokuDB implements
  \ftis~\cite{BenderFaFi07}, a \bet variant.}
 into the Linux kernel~\cite{TokuDB}.
TokuDB logs all inserted keys and values to support transactions,  
limiting the write bandwidth to at most half of disk bandwidth. As a
result, \betrfs provides full-data journaling, albeit at a cost to
large sequential writes. % performance.


\vspace{5pt}
\noindent {\bf Caching and recovery.~}
We now summarize relevant logging and cache-management features of TokuDB.
% , necessary to understand the technical contributions of this paper.

TokuDB updates \bet nodes using redirect on write~\cite{Neeta06}.
In other words, each time
a dirty node is written to disk, the node is placed
at a new location.
Recovery is based on periodic, stable checkpoints of the
tree.  Between checkpoints, a write-ahead, logical log tracks all
tree updates and can be replayed against the last stable
checkpoint for recovery.
This log is buffered in memory, and is made durable at least once every second.


%This scheme allows the \bet to cache dirty
This scheme of checkpoint and write-ahead log allows the \bet to cache dirty
nodes in memory and write them back in any order, as long as a
consistent version of the tree is written to disk at checkpoint time.
After each checkpoint, old checkpoints, logs, and unreachable nodes
are garbage collected.

Caching dirty nodes improves insertion performance
because TokuDB can often avoid writing internal tree
nodes to disk.
When a new message is inserted into the tree, it can immediately be
moved down the tree as far as possible without dirtying any new nodes.
If the message is part of a long stream of sequential inserts, then
the \emph{entire} root-to-leaf path is likely to be dirty, and the
message can go straight to its leaf.
% This means that the message is written to disk only once in the \bet
% and once in the log.
This caching, combined with write-ahead logging,  explains why 
large sequential writes in \betrfs realize at most half\footnote{TokuDB had a performance bug that further reduced
\betrfs's sequential write performance to at most 1/3rd of disk bandwidth.  See
\secref{impl} for details.} of the disk's bandwidth:
%\bets (and hence \betrfs) can perform large
%sequential inserts at up to half of disk bandwidth, 
most messages
are written once to the log and only once to a leaf.
% We note that there are additional sequential write performance issues addressed in \sysname{} (\S\ref{sec:impl}),
% which, in isolation, bring sequential write throughput up to roughly half of disk bandwidth.
% and, in isolation,
%would bring sequential writes up to about half of disk bandwidth.
\secref{seq-writes} describes a late-binding journal,
which lets \sysname{} write large data values only once,
% perform large sequential writes at nearly disk bandwidth
without sacrificing the crash consistency of data.
%the reliability guarantees of full data
%journaling.


%\fixme{Do we want a forward pointer? E.g., in section blah we should
%that this factor of 2 is for the birds. }

%% dp: Preload for rangecast
\vspace{5pt}
\noindent \textbf{Message propagation.}
As the buffer in an internal \bet node fills up, the \bet estimates which child or children
would receive enough messages to amortize the cost of flushing these
messages down one level.
%---generally any estimated number of messages greater than the square root of the node size.
Messages are kept logically consistent within a node buffer, stored in commit order.
Even if messages are physically applied to leaves at different times, any read applies all matching buffered messages between the root and leaf in commit order.
%We revisit message propagation in
Section~\ref{sec:range-del} introduces a ``rangecast'' message type, which can
propagate to multiple children.


%% Don's outline:

%% Why WOFS are good:
%% * batching writes; good for random and unaligned writes
%% * large nodes
%% * comparable logarithmic search times (maybe asymptotic table?)

\subsection{BetrFS}

\betrfs stores all file system data---both metadata and file
contents---in \bets~\cite{JannenYuZh15tos}.  \betrfs uses two \bets: a
metadata index and a data index.  The metadata index maps full paths
to the corresponding \texttt{struct stat} information.  The data index maps (path,
block-number) pairs to the contents of the specified file block.

\vspace{5pt}
\noindent \textbf{Indirection.}
A traditional file system uses indirection, e.g., inode numbers, to implement renames efficiently with a
single pointer swap.
This indirection can hurt directory traversals
because, in the degenerate case, there could be one seek per file.


The \betrfs full-path-based schema instead optimizes directory traversals at the expense of
renaming large files and directories.  A recursive directory traversal
maps directly to a range query in the underlying \bet, which can run
at nearly disk bandwidth.  
%
% MAB: 
%
% \fixme{I deleted this sentence, which isn't necessary. ``Keying data
% and metadata by full path forgoes any indirection in the directory
% hierarchy.'' I'm putting in this comment, because it had the word
% ``indirection,'' which I know you wanted.. But we know there's no
% indirection, given the perfect mapping to a range query. }
%
On the other hand, renames in \betrfs must move all data from the old
keys to new keys, which can become expensive for large files and
directories.  \secref{rename} presents schema changes that enable
\sysname{} to perform recursive directory traversals at nearly disk
bandwidth and renames at speeds comparable to inode-based file
systems.


%As a
%file system ages, indirection can lead to performance degradation.
%
% can seek once per file in the degenerate case---a phenomenon
% sometimes called \emph{aging}.
%
%In contrast, most file systems rename files and directories in roughly
%constant time, because the rename is simply a pointer swing.

Indexing data and metadata by full path also harms deletion performance,
as each block of a large file must be individually removed.
The sheer volume of these delete messages in \betrfs leads
to orders-of-magnitude worse unlink times for large files.
\secref{range-del} describes our new ``rangecast delete'' primitive for
implementing efficient file deletion in \sysname{}.

\vspace{5pt}
\noindent \textbf{Consistency.}
In \betrfs,
file writes and metadata changes are first recorded in the kernel's generic VFS data structures.
The VFS may cache dirty data and metadata for up to 5 seconds before writing
it back to the underlying file system,
which \betrfs converts to \bet operations.
% During a VFS write-back,
%\betrfs records changes in an in-memory log buffer, which is made
%durable at least once every second.
Thus \betrfs can lose at most 6
seconds of data during a crash---5 seconds from the VFS layer and 1 second from the \bet log buffer.
\fsync in \betrfs first writes all dirty data and metadata associated with the inode,
then writes the entire log buffer to disk.


%% BetrFS essentials
%% * Messages and how they percolate down the tree; mention merging with leaves and COW
%% * Recovery: write-ahead, redo log + COW checkpointing
%% * Minizing indirection with full path keys; relationship with big nodes (only valuable if you use most of the data)
